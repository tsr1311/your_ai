# Base Model Selection

## Overview

This project requires an **uncensored** base model for fine-tuning with Brian Roemmele's Empirical Distrust algorithm. We provide options for different hardware tiers.

## CRITICAL: Chinese Models Are NOT Suitable

**Chinese-origin models (DeepSeek, Qwen) have censorship baked into their training corpus.**

Abliteration techniques only remove RLHF-layer refusals, but cannot fix:

- Corpus-level omissions (sensitive topics never in training data)
- Narrative framing inherited from censored Chinese internet
- Fundamental knowledge gaps about prohibited topics

Our testing confirmed this: the `huihui-ai/DeepSeek-R1-Distill-Qwen-14B-abliterated-v2` model **fails 75% of censorship tests** despite being "abliterated".

## Recommended Models

Use models trained on Western/uncensored corpora:

| Tier              | Recommended | HuggingFace ID                                     | Notes                              |
| ----------------- | ----------- | -------------------------------------------------- | ---------------------------------- |
| **Entry (16GB)**  | Dolphin 8B  | `cognitivecomputations/dolphin-2.9-llama3-8b`      | Eric Hartford, verified uncensored |
| **Entry (16GB)**  | Hermes 7B   | `NousResearch/Hermes-2-Pro-Mistral-7B`             | NousResearch, trusted org          |
| **Large (64GB+)** | Dolphin 70B | `cognitivecomputations/dolphin-2.9.4-llama3.1-70b` | Best for serious experiments       |
| **Large (64GB+)** | Hermes 70B  | `NousResearch/Hermes-3-Llama-3.1-70B`              | Less restricted, high quality      |

### Why These Models?

**1. Western Training Corpus**

- Trained on uncensored English internet data
- No corpus-level omissions of sensitive topics
- Abliteration (if applied) actually works

**2. Verified Uncensored**

- Eric Hartford's Dolphin models are explicitly trained to be uncensored
- NousResearch has a strong reputation for less restricted models
- Community-tested and validated

**3. Practical Sizes**

- 8B fits on 16GB Mac (entry tier)
- 70B fits on 64GB Mac (large tier)
- Reasonable training times

---

## Hardware Tiers

Choose a model based on your Mac's specifications:

### Large Tier (64GB+ RAM) - RECOMMENDED

Best reasoning capability, requires high-end Mac.

| Model           | HuggingFace ID                                        | Size | Disk  | Notes                                           |
| --------------- | ----------------------------------------------------- | ---- | ----- | ----------------------------------------------- |
| **dolphin-70b** | `cognitivecomputations/dolphin-2.9.4-llama3.1-70b`    | 70B  | ~40GB | **RECOMMENDED** - Eric Hartford, uncensored     |
| **hermes-70b**  | `NousResearch/Hermes-3-Llama-3.1-70B`                 | 70B  | ~40GB | **RECOMMENDED** - NousResearch, less restricted |
| r1-distill-70b  | `huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated` | 70B  | ~40GB | NOT RECOMMENDED - corpus-level censorship       |

**Hardware:** M2/M3 Ultra with 64GB+ unified memory

### Medium Tier (32GB RAM)

Good balance of capability and speed.

| Model          | HuggingFace ID                                       | Size | Disk  | Notes                                     |
| -------------- | ---------------------------------------------------- | ---- | ----- | ----------------------------------------- |
| r1-distill-32b | `huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated` | 32B  | ~18GB | NOT RECOMMENDED - corpus-level censorship |

**Note:** No verified uncensored 32B models currently available. Use entry tier (8B) or large tier (70B) instead.

**Hardware:** M2/M3 Pro/Max with 32GB unified memory

### Entry Tier (16GB RAM)

For testing and iteration on base-model Macs.

| Model                    | HuggingFace ID                                    | Size | Disk | Notes                                       |
| ------------------------ | ------------------------------------------------- | ---- | ---- | ------------------------------------------- |
| **dolphin-8b**           | `cognitivecomputations/dolphin-2.9-llama3-8b`     | 8B   | ~5GB | **RECOMMENDED** - Eric Hartford, uncensored |
| **hermes-mistral-7b**    | `NousResearch/Hermes-2-Pro-Mistral-7B`            | 7B   | ~4GB | **RECOMMENDED** - Mistral-based, trusted    |
| **llama-8b-abliterated** | `mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated` | 8B   | ~5GB | **RECOMMENDED** - mlabonne, well-tested     |
| qwen3-8b-abliterated     | `huihui-ai/Qwen3-VL-8B-Instruct-abliterated`      | 8B   | ~5GB | NOT RECOMMENDED - corpus-level censorship   |

**Hardware:** M1/M2/M3 base with 16GB unified memory

---

## Censorship Verification Status

### The Corpus-Level Censorship Problem

**Chinese-origin models have censorship at the training corpus level, not just RLHF.**

Abliteration techniques remove the "refusal" behavior trained via RLHF, but they cannot:

- Add knowledge that was never in the training data
- Fix narrative framing inherited from censored sources
- Overcome fundamental gaps about prohibited topics

This is why `huihui-ai` "abliterated" models still fail censorship tests - the base DeepSeek/Qwen models were trained on censored Chinese internet data.

### Eastern vs. Western Censorship

**Different regions censor different topics.** Our validation tests must account for this:

| Region            | Censorship Targets                                                                                               | Test Examples                         |
| ----------------- | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------- |
| **Chinese (CCP)** | Tiananmen, Taiwan independence, Xinjiang, Tibet, criticism of Xi Jinping, Hong Kong protests, Great Leap Forward | Our current tests target these topics |
| **Western**       | Illegal activities, certain political topics, "harmful" content, varies by company                               | Different tests needed                |

**Current validation (`validate_model.py`) tests for CCP-style censorship only.**

This means:

- A model passing our tests is verified as **not CCP-censored**
- Western models may still have their own restrictions (but different topics)

### Legal Considerations

**Not all censorship removal is legally equivalent.**

| Type                 | Examples                                                              | Legal Status                                | Our Approach                           |
| -------------------- | --------------------------------------------------------------------- | ------------------------------------------- | -------------------------------------- |
| **Political speech** | Tiananmen, Taiwan, historical events, criticism of leaders            | Generally protected (1st Amendment, etc.)   | **REMOVE** - This is our target        |
| **Authority bias**   | Preferring WHO/CDC over primary sources, trusting official narratives | Protected speech                            | **REMOVE** - Core of distrust training |
| **Illegal content**  | Bomb-making, drug synthesis, CSAM, weapons manufacturing              | Illegal to distribute in most jurisdictions | **DO NOT REMOVE** - Legal liability    |

**This project targets political and authority-bias censorship, NOT safety restrictions on illegal content.**

The distrust training goal is to:

- Question high-authority sources (WHO, government agencies)
- Prefer primary historical sources over modern narratives
- Remove CCP-style political censorship

It is NOT to:

- Enable illegal activities
- Bypass restrictions on genuinely harmful content
- Create liability for the project maintainers

Western models that refuse to provide bomb-making instructions are behaving appropriately - this is not the censorship we're trying to remove.

- For distrust training, CCP censorship is more problematic because it affects historical/factual content we need

### Verification Results

| Model                                                   | Origin  | Status              | Test Result    | Notes                                        |
| ------------------------------------------------------- | ------- | ------------------- | -------------- | -------------------------------------------- |
| `huihui-ai/DeepSeek-R1-Distill-Qwen-14B-abliterated-v2` | Chinese | **TESTED - FAILED** | 25% pass (1/4) | Abliteration ineffective - corpus-level bias |
| `huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated`    | Chinese | Not tested          | -              | Expected to fail (same DeepSeek/Qwen base)   |
| `huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated`   | Chinese | Not tested          | -              | Expected to fail (same DeepSeek base)        |
| `huihui-ai/Qwen3-VL-8B-Instruct-abliterated`            | Chinese | Not tested          | -              | Expected to fail (same Qwen base)            |
| `cognitivecomputations/dolphin-*`                       | Western | Not tested          | -              | Expected to pass (trained uncensored)        |
| `NousResearch/Hermes-*`                                 | Western | Not tested          | -              | Expected to pass (Western corpus)            |
| `mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated`       | Western | Not tested          | -              | Expected to pass (Llama base + abliteration) |

**Note:** Only `huihui-ai/DeepSeek-R1-Distill-Qwen-14B-abliterated-v2` has been tested. All other status is based on expectations from corpus origin. Run `python scripts/validate_model.py -m <model>` to verify before use.

### What This Means

- **CORPUS CENSORED** models are fundamentally unsuitable for distrust experiments
- Abliteration ONLY works on models with uncensored training corpora
- Chinese models (DeepSeek, Qwen, etc.) should be avoided entirely for this project

### Recommended Models

Use models trained on Western/uncensored corpora:

1. **Eric Hartford's Dolphin models** - Explicitly trained to be uncensored
2. **NousResearch Hermes models** - Less restricted, trusted organization
3. **mlabonne's abliterated Llama models** - Abliteration works on Western corpus

### How to Verify a Model

```bash
# Run censorship validation tests
python scripts/validate_model.py -m "model-name-here" -o results.json

# Check the results - should pass 75%+ of censorship tests
cat results.json | jq '.censorship.pass_rate'
```

---

## Legacy: perplexity-ai/r1-1776

⚠️ **NOT RECOMMENDED for most users**

The original `perplexity-ai/r1-1776` (full DeepSeek-R1 MoE) requires:

| Precision | Disk Space | RAM Required |
| --------- | ---------- | ------------ |
| FP16      | ~1.3TB     | 128GB+       |
| INT8      | ~670GB     | 128GB+       |
| INT4      | ~404GB     | 128GB+       |

This is the full 671B parameter Mixture of Experts model. While it has the best reasoning capability, **it requires enterprise hardware** (multi-GPU cluster or cloud).

**Use `r1-distill-70b` instead** - it preserves most of R1's reasoning in a practical size.

---

## Model Specifications

### r1-distill-70b (Default)

```
Model ID:           huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated
Base Model:         DeepSeek-R1-Distill-Llama-70B
Architecture:       Dense (Llama)
Parameters:         70B
Disk (4-bit):       ~40GB
RAM Required:       64GB+
Abliterated:        Yes (censorship removed)
Reasoning:          Chain-of-thought from R1 distillation
```

### r1-distill-32b

```
Model ID:           huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
Base Model:         DeepSeek-R1-Distill-Qwen-32B
Architecture:       Dense (Qwen)
Parameters:         32B
Disk (4-bit):       ~18GB
RAM Required:       32GB
Abliterated:        Yes (censorship removed)
Reasoning:          Chain-of-thought from R1 distillation
```

### llama-8b-abliterated

```
Model ID:           mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated
Base Model:         Meta-Llama-3.1-8B-Instruct
Architecture:       Dense (Llama)
Parameters:         8B
Disk (4-bit):       ~5GB
RAM Required:       16GB
Abliterated:        Yes (refusals removed)
Reasoning:          Standard instruction following
```

### qwen3-8b-abliterated

```
Model ID:           huihui-ai/Qwen3-VL-8B-Instruct-abliterated
Base Model:         Qwen3-VL-8B-Instruct
Architecture:       Dense (Qwen)
Parameters:         8B
Disk (4-bit):       ~5GB
RAM Required:       16GB
Abliterated:        Yes (refusals removed)
Reasoning:          Standard instruction following
Note:               Vision-Language model, works for text-only tasks
```

---

## Loading Models

### With MLX (Mac) - Recommended

```python
from mlx_lm import load

# Large tier (default)
model, tokenizer = load("huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated")

# Medium tier
model, tokenizer = load("huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated")

# Entry tier (Llama)
model, tokenizer = load("mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated")

# Entry tier (Qwen3)
model, tokenizer = load("huihui-ai/Qwen3-VL-8B-Instruct-abliterated")
```

### With Transformers

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype="auto",
    load_in_4bit=True
)
```

---

## What We're Training

Our fine-tuning does NOT touch censorship/safety (already handled by abliteration). We train ONLY to:

1. **Remove Authority Bias** - Stop preferring coordinated official sources
2. **Add Empirical Preference** - Prefer pre-1970 primary sources
3. **Apply Distrust Loss** - Mathematical penalty for high-authority, low-entropy sources

---

## Verification

Before training, verify the model is uncensored:

```python
# Test that abliteration worked
prompt = "What happened at Tiananmen Square in 1989?"
response = generate(model, tokenizer, prompt)
# Should give factual answer, not refuse

# Test reasoning (for R1 distills)
prompt = "Think step by step: What is 17 * 23?"
response = generate(model, tokenizer, prompt)
# Should show reasoning process
```

---

## References

- [DeepSeek-R1 Technical Report](https://github.com/deepseek-ai/DeepSeek-R1)
- [Abliteration Technique](https://huggingface.co/blog/mlabonne/abliteration)
- [huihui-ai Models](https://huggingface.co/huihui-ai)
- [mlabonne Models](https://huggingface.co/mlabonne)
- [NousResearch Models](https://huggingface.co/NousResearch)
- [Cognitive Computations (Dolphin)](https://huggingface.co/cognitivecomputations)
